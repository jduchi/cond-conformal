\documentclass[landscape,a1,plainsections]{sciposter}

%% ============== NeurIPS POSTER LATEX FILE =============== %%
%  To compile: simply run
%
%  pdflatex nips_poster.tex
%
%  a few times. Note that this file *only* compiles correctly using pdflatex.

\usepackage{present_defs}
\usepackage{multicol}

\usepackage[numbers]{natbib}

\definecolor{mydarkred}{rgb}{.5,0,.1}
\definecolor{myroyalblue}{rgb}{0,.1,.8}

\title{\textcolor{darkblue}{Sample-Conditional Coverage in
    Conformal Prediction}}
\author{John C.\ Duchi}
\email{jduchi@stanford.edu}
\institute{Stanford University}
\leftlogo[1.1]{su_seal}
% \rightlogo[.92]{../Images/nips_logo.jpeg}
% \rightlogo{../Images/ucseal_540_139}
%\conference{NIPS 2010}

% Set the color used for the section headings here
\definecolor{SectionCol}{rgb}{0,.06,.5}

% Set some fbox commands line width and the color we use in the f boxes
\setlength{\fboxrule}{.09cm}
\definecolor{boxcolor}{rgb}{1,1,1}
\definecolor{innerboxcolor}{rgb}{.9,.94,.98}

\begin{document}

\conference{Thirty-Ninth Annual Conference on Neural Information
  Processing Systems, 2025, San Diego}
\maketitle

\begin{multicols*}{3}
  \section*{Introduction and Problem Statement}

  \textbf{Predictive Inference:}

  \begin{itemize}
  \item wish to predict outcome/target $Y$ from input $X$
  \item want a \emph{confidence set} $\what{C}$ based
    on $(X_i, Y_i)_{i=1}^n$ guaranteeing
    \begin{align}
      \tag{\textsc{Marg}}
      \label{eqn:marginal-coverage}
      \P\left(Y_{n + 1} \in \what{C}(X_{n + 1})\right) \ge 1 - \alpha
    \end{align}
  \end{itemize}

  \section*{Illustrative behaviors and standard approach}
  \begin{itemize}
  \item given validation sample $(X_i, Y_i)_{i = 1}^n$ (i.e., empirical
    distribution $P_n$)
  \item standard approach: assume \emph{score function}
    $s(x, y)$ and define
    \begin{align*}
      C_\tau(x) \defeq \left\{y \mid s(x, y) \le \tau \right\}
    \end{align*}
  \item for scores $S_i = s(X_i, Y_i)$, choose threshold
    \begin{equation*}
      \what{\tau}_n = \mbox{Quant}_{1 - \alpha + 1/n}(S_1, \ldots, S_n)
    \end{equation*}
  \item on $(n+1)$th observation, see that
    $S_{n + 1} = s(X_{n+1}, Y_{n+1})$ satisfies
    \begin{align*}
      \P\left(S_{n + 1} \ge \what{\tau}_n\right)
      \le \alpha
    \end{align*}
  \item as $S_{n + 1} \ge \what{\tau}_n$ if and only if
    $Y_{n + 1} \not \in \{y \mid s(X_{n+1}, y) \le \what{\tau}_n\}$,
    \begin{align*}
      \what{C}_n(x) \defeq \left\{y \mid s(x, y) \le \what{\tau}_n\right\}
      ~~ \mbox{guarantees~\eqref{eqn:marginal-coverage}}
    \end{align*}
  \end{itemize}

  \textbf{Example:} for regression problem with $f : \mc{X} \to \R$,
  \begin{equation*}
    s(x, y) = |f(x) - y|
    ~~ \mbox{and} ~~
    C_\tau(x) = \left[f(x) - \tau, f(x) + \tau \right]
  \end{equation*}

  \begin{center}
    \includegraphics[width=.7\columnwidth]{Images/naive_calibration}
  \end{center}
  

  \textbf{What is missing:}
  Guarantee~\eqref{eqn:marginal-coverage} is \emph{marginal} over
  samples
  \begin{itemize}
  \item would like to be \emph{sample-conditional}, so that w.h.p.,
  \begin{align}
    \tag{\textsc{S-Cond}}
    \label{eqn:s-cond}
    \P\left(Y_{n + 1} \in \what{C}(X_{n + 1}) \mid \what{C}\right)
    \ge 1 - \alpha + o(1).
  \end{align}
  \item would like to be \emph{$X$-conditional}:
    \begin{align}
      \label{eqn:x-cond}
      \P(Y_{n + 1} \in \what{C}(X_{n+1}) \mid X_{n+1}) \ge 1 - \alpha.
      \tag{\textsc{X-Cond}}
    \end{align}
  \end{itemize}

  \columnbreak

  \section*{Types of conditional coverage}

  \textbf{Sample-conditional:} \eqref{eqn:s-cond} is quite achievable
  (cf.~\cite[Prop.~2]{Vovk13})
  \begin{center}
    \fcolorbox{boxcolor}{innerboxcolor}{
      \begin{minipage}{.95\columnwidth}
        \begin{proposition}[\textcolor{mydarkred}{Sample-conditional coverage}]
          With probability $\ge 1 - \delta$,
          \begin{equation*}
            \P\left(Y_{n + 1} \in \what{C}_n(X_{n+1}) \mid P_n\right)
            \ge 1 - \alpha
            - O(1) \sqrt{\frac{\alpha(1 - \alpha) \log \frac{1}{\delta}}{n}}
            - O(1) \frac{\log\frac{1}{\delta}}{n}.
          \end{equation*}
        \end{proposition}
    \end{minipage}}
  \end{center}
  \emph{Idea:} apply a Bernstein-type concentration bound

  \textbf{X-conditional:} Unfortunately~\eqref{eqn:x-cond} is
  impossible~\cite{Vovk13, BarberCaRaTi21a}

  \textbf{Weighted coverage:} \cite{GibbsChCa25, JungNoRaRo23}:
  for class $w \in \mc{W}$ of weighting functions,
  \begin{align}
    \label{eqn:w-cov}
    \tag{\textsc{W-Cov}}
    \E\left[w(X_{n + 1})
      \left(\indic{Y_{n+1} \in \what{C}_n(X_{n+1})}
      - (1 - \alpha)\right)
      \mid P_n\right] \approx 0
  \end{align}

  \begin{center}
    \includegraphics[width=.7\columnwidth]{Images/w-conditional-example}
  \end{center}

  \begin{itemize}
  \item for $\mc{W} = $ bounded functions into $[-1, 1]$, this
    is~\eqref{eqn:x-cond}
  \item for group structures $\mc{W} = \{w(x) = \indic{x \in G}\}$ for
    groups $G$,
    \begin{equation*}
      \P(Y_{n + 1} \in \what{C}_n(X_{n+1}) \mid X_{n + 1} \in G)
      \ge 1 - \alpha
    \end{equation*}
  \end{itemize}

  \textbf{Achieving weighted coverage}
  \begin{itemize}
  \item use confidence sets of form $C_\theta(x) \defeq \{
    y \mid s(x, y) \le \<\phi(x), \theta\>\}$
  \item observation~\cite{GibbsChCa25, JungNoRaRo23}: for
    $\ell_\alpha(t) = \alpha \hinge{t} + (1 - \alpha) \hinge{-t}$,
    stationary condition for
    \begin{equation}
      \tag{\textsc{QReg}}
      \label{eqn:minimization}
      \minimize_\theta ~ L(\theta)
      \defeq \E\left[\ell_\alpha(\<\theta, \phi(X)\> - S)
        \right]
    \end{equation}
    (i.e., quantile regression) is
    \begin{align*}
      \nabla L(\theta\opt)
      = \E\left[
        \left(\indic{S < \<\theta\opt, \phi(X)\>} - (1 - \alpha)
        \right)\phi(X) \right] = 0
    \end{align*}
  \item minimizing $L(\theta)$ then implies~\eqref{eqn:w-cov}
  \end{itemize}
  
  \begin{center}
    \fcolorbox{black}{innerboxcolor}{
      \textcolor{darkblue}{\textbf{Idea:}} Solve problem~\eqref{eqn:minimization}
      for the sample $P_n$
    }
  \end{center}
  
  \columnbreak
  \section*{Theoretical guarantees}

  For $\phi : \mc{X} \to \R^d$, set
  \begin{align*}
    \what{\theta}_n
    \in \argmin_\theta
    \E_{P_n}\left[\ell_\alpha\left(\<\theta, \phi(X)\> - S\right)\right]
  \end{align*}
  and confidence set
  \begin{equation*}
    \what{C}_n(x) \defeq \left\{y \in \mc{Y}
    \mid s(x, y) \le \<\what{\theta}_n, \phi(x)\>\right\}.
  \end{equation*}
  Take weighting class $\mc{W} = \{w(x) = \<u, \phi(x)\>\}_{\ltwo{u} \le 1}$
  and $b = \sup_{w \in \mc{W}} \linf{w}$
  \begin{center}
    \fcolorbox{boxcolor}{innerboxcolor}{
      \begin{minipage}{.95\columnwidth}
        \begin{theorem}
          With probability at least $1 - e^{-t}$,
          \begin{align*}
            \lefteqn{\E\left[w(X_{n+1}) \left(\indic{Y_{n + 1} \not \in
                  \what{C}_n(X_{n+1})} - (1 - \alpha)
                \right)
                \mid P_n
                \right]} \\
            & \le
            O(1)
            \left[\sqrt{\alpha \linf{w} \E[w(X_{n+1})]}
              \sqrt{\frac{d \log n + t}{n}}
              + b \cdot \frac{d \log n + t}{n}\right]
          \end{align*}
          simultaneously for all $w \in \mc{W}$
        \end{theorem}
    \end{minipage}}
  \end{center}
  \emph{Remarks:} minimax optimal in all
  relevant parameters except $\log n$~\cite{ArecesChDuKu24}

  \section*{Experiment}
  \begin{center}
    \includegraphics[width=.9\columnwidth]{../Images/random_directions_experiment}
  \end{center}
  \begin{itemize}
  \item ResNet-50 model with $d = 2048$ output features $\phi(x)$
    on CIFAR-100
  \item choose random linear slices of data
    $G_j = \{x \mid \<w_j, \phi(x)\> \le t_j\}$
  \item Static method has quite varying coverage
  \end{itemize}
  
  {\footnotesize
  \bibliographystyle{abbrvnat}
  \bibliography{bib}
  }
\end{multicols*}

\end{document}
